{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd360d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link 1\n",
      "25 schools pulled\n",
      "[['Indiana Connections Academy', 'IN', '46278', 6687, 'Online'], ['Granada Hills Charter', 'CA', '91344', 5462, '$65,290'], ['North Star Academy Charter School of Newark', 'NJ', '07102', 6298, '$37,675'], ['Brooklyn Technical High School', 'NY', '11217', 5943, '$97,055'], ['Ohio Connections Academy', 'OH', '44114', 5709, 'Online'], ['Hendry Virtual Instruction Program', 'FL', '33935', 6490, 'Online'], ['South Carolina Connections Academy', 'SC', '29210', 6298, 'Online'], ['Volusia Virtual Instruction Program District Provided', 'FL', '32129', 7573, 'Online'], ['Visions in Education', 'CA', '95608', 7189, '$70,684'], ['Idaho Home Learning Academy', 'ID', '83252', 7003, 'Online'], ['Blue Ridge Academy', 'CA', '93252', 6967, 'Online'], ['Primavera - Online', 'AZ', '85225', 7046, 'Online'], ['River Springs Charter School', 'CA', '92590', 7363, '$98,631'], ['Agora Cyber Charter School', 'PA', '19406', 7337, 'Online'], ['Reach Cyber Charter School', 'PA', '17111', 8138, 'Online'], ['Texas Connections Academy at Houston', 'TX', '77042', 8022, 'Online'], ['Arizona Virtual Academy', 'AZ', '85305', 7647, 'Online'], ['Interior Distance Education of Alaska (Idea)', 'AK', '99701', 9216, '$76,464'], ['Blue Peak High School', 'UT', '84074', 8701, '$65,740']]\n",
      "71.92163753509521\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import csv\n",
    "from urllib.parse import urlencode\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name, state, zipcode, students, income):\n",
    "        self.name = name\n",
    "        self.state = state\n",
    "        self.zipcode = zipcode\n",
    "        self.students = students\n",
    "        self.income = income\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "def extract_source(url):\n",
    "    params = {'api_key': API_KEY, 'url': url}\n",
    "    for _ in range(NUM_RETRIES):\n",
    "        try:\n",
    "            response = requests.get('http://api.scraperapi.com/', params=urlencode(params))\n",
    "            if response.status_code in [200, 404]:\n",
    "                break\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            response = ''\n",
    "    if response.status_code == 200:\n",
    "        source = response.text\n",
    "    return source\n",
    "\n",
    "def extract_link(source):\n",
    "    links = []\n",
    "    soup=BeautifulSoup(source, features=\"html.parser\")\n",
    "    school=soup.find_all('li', class_ = \"search-results__list__item\")\n",
    "    for x in school:\n",
    "        school = None\n",
    "        for y in x.find_all('a', class_ = \"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineNone search-result__link nss-cyqlwo\"):\n",
    "            school = y['href']\n",
    "            links.append(school)\n",
    "    return links\n",
    "\n",
    "def scrape_url(url):\n",
    "    soup = BeautifulSoup(extract_source(url), features=\"html.parser\")\n",
    "    name = soup.find('h1', class_ = \"postcard__title\").text\n",
    "    address = soup.find('address', class_ = \"profile__address--compact\").text\n",
    "    state = address[-8:-6]\n",
    "    zipcode = address[-5:]\n",
    "    students = soup.find('section', class_ = \"block--two-poll\")\n",
    "    if students is None:\n",
    "        students = soup.find('section', class_ = \"block--two-poll--no-poll block--two-poll--expansion\")\n",
    "        students = students.find('div', class_ = \"scalar__value\").text\n",
    "    else:\n",
    "        students = students.find('div', class_ = \"scalar__value\").text\n",
    "    income = soup.find_all('div', class_ = \"profile__bucket--5\")\n",
    "    if len(income) == 1:\n",
    "        income = 'Online'\n",
    "    else:\n",
    "        income = income[1].text\n",
    "        start = income.find('$')\n",
    "        end = income.find(',')+4\n",
    "        income = income[start:end]\n",
    "    data.append([name, state, zipcode, students, income])\n",
    "\n",
    "API_KEY = '006192aace270d7f21e27e69f9bc1c1f'\n",
    "NUM_RETRIES = 5\n",
    "NUM_THREADS = 5\n",
    "page_beg = 'https://www.niche.com/k12/search/largest-public-high-schools/?page='    \n",
    "fields = ['Name', 'State', 'Zip Code', 'Students', 'Income']\n",
    "data = []\n",
    "schools = []\n",
    "\n",
    "def buildTree(data):\n",
    "    if len(data) == 0:\n",
    "        return\n",
    "    middle, students = len(data) // 2, data[len(data) // 2][3]\n",
    "    students = int(students.replace(',', ''))\n",
    "    new_node = Node(data[middle][0], data[middle][1], data[middle][2], students, data[middle][4])\n",
    "    new_node.left = buildTree(data[:middle])\n",
    "    new_node.right = buildTree(data[middle+1:])\n",
    "    return new_node\n",
    "\n",
    "def findSchool(root, limit):\n",
    "    if not root:\n",
    "        return\n",
    "    if root.students < limit:\n",
    "        schools.append([root.name, root.state, root.zipcode, root.students, root.income])\n",
    "    findSchool(root.left, limit)\n",
    "    findSchool(root.right, limit)\n",
    "\n",
    "with open('test.csv', 'w', newline = '') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(fields)\n",
    "    for i in range(1,3):\n",
    "        page = page_beg + str(i)\n",
    "        start = time.time()\n",
    "        print(\"Link \" + str(i))\n",
    "        links = extract_link(extract_source(page))\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "            executor.map(scrape_url, links)\n",
    "        data.sort(key= lambda x: x[3])\n",
    "        write.writerows(data)\n",
    "        print(str(len(data)) + \" schools pulled\")\n",
    "        tree = buildTree(data)\n",
    "        findSchool(tree, 10000)\n",
    "        print(schools)\n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        data = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
